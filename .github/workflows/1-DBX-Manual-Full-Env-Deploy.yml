# yaml-language-server: $schema=https://json.schemastore.org/github-workflow.json

#https://github.com/marketplace/actions/run-databricks-notebook


# TO DO: Write A New Package For Setting Environment Variables From A Parameters File

name: DBX_CICD-DEPLOY

on: push 

#on: [workflow_dispatch] 

permissions:
      id-token:               write
      contents:               read

jobs:
  DBX_CICD_Deployment:
      name:                     DBX_CICD_Deployment
      runs-on:                  ubuntu-latest
      strategy:
        matrix:
          environments:          [Development, UAT, PreProduction, Production]    
      steps:
        - uses:                  actions/checkout@v3

        # az ad sp create-for-rbac -n DevOpsAgentSP --role Owner --scopes /subscriptions/4f1bc772-7792-4285-99d9-3463b8d7f994 --sdk-auth
        
        # Login To testappciaran. This Has Higher Privileges/ Ownership To Create Resources/RBACs. We Generally Wouldn't Be Given 
        # SP Secrets etc. As This Would Confer Too Much Power. Super Users Will Use This Login. DBX SP should have contributor rights.
        
        # It is important to set up federated connections (below)
        # https://goodworkaround.com/2021/12/21/another-deep-dive-into-azure-ad-workload-identity-federation-using-github-actions/


        - name:                 Azure Login - ${{ matrix.environments }}
          uses:                 azure/login@v1
          with:
            creds:              ${{secrets.AZURE_CREDENTIALS}} 
      

        - name:                 Store Pipeline Param JSON File Variables As Environ Variables
          uses:                 antifree/json-to-variables@v1.0.1
          with:
            filename:           '.github/workflows/Pipeline_Param/${{ matrix.environments }}.json'
            prefix:             param

        - name:                 Store BICEP Param JSON File Variables As Environ VariablesStore JSON Param File Variables As Environ Variables
          uses:                 antifree/json-to-variables@v1.0.1
          with:
            filename:           'Infrastructure/DBX_CICD_Deployment/Bicep_Params/${{ matrix.environments }}/Bicep.parameters.json'
            prefix:             param



        #- name:                 Deploy DBX CICD Azure Resources
        #  run:                  bash ./.github/workflows/Utilities/Utils-Azure-Resources.sh
        #  env:
        #    environment:        ${{ matrix.environments }}


        - name:                 Assign RBAC Permissions 
          run:                  sh ./.github/workflows/Utilities/Utils-Assign-RBAC.sh
          env:
            environment:        ${{ matrix.environments }}

        # Switch To DBX SP.

        # Day To Day Use Interacting With Databricks API Does Not Require God Rights dbxsp. The Principal of Zero Trust Applies.
        
        # Therefore We Use The DBX SP (Only Has Databricks Custom Role Assignments - No Owner Permissions etc), For Interacting With Databricks...
        # API To Create Clusters/ Jobs etc. Might be worth giving sp contributor right.


        - name:                 Authenticate to DBX Service Principal
          run:                  bash ./.github/workflows/Utilities/Utils-DBX-SP-Authenticate.sh
          env:
            ARM_CLIENT_ID:      ${{ secrets.ARM_CLIENT_ID }}
            ARM_CLIENT_SECRET:  ${{ secrets.ARM_CLIENT_SECRET }}
            ARM_TENANT_ID:      ${{ secrets.ARM_TENANT_ID }}

            
        - name:                 Setup Python
          uses:                 actions/setup-python@v4
          with:
            python-version:     '3.8'


        - name:                 Create And Store PAT Token In Key Vault
          run:                  bash ./.github/workflows/Utilities/Utils-Create-PAToken.sh


        - name:                 Create DBX Secret Scopes
          run:                  bash ./.github/workflows/Utilities/Utils-Create-Scope.sh
        

        - name:                 Create DBX Clusters
          run:                  bash ./.github/workflows/Utilities/Utils-Create-Cluster.sh
          env:
            environment:        ${{ matrix.environments }}


        - name:                 Create DBX Repos
          run:                  bash ./.github/workflows/Utilities/Utils-Create-Repo-Folders.sh
          env:
            environment:        ${{ matrix.environments }}
            PAT_GIT:            ${{ secrets.PAT_GIT }}


        - name:                   Install + Configure Databricks CLI
          run:                    bash ./.github/workflows/Utilities/Utils-DBX-CLI-Configure.sh











































            # Navigate To The Setup.Py File.
            #ls
            #cd src
            #cd pipelines
            #cd dbkframework

            # Create The Python Wheel File
            #python setup.py sdist bdist_wheel

            #cd dist
            #echo "Name of Pyton Wheel File"
            #ls

            #databricks fs -h
            #databricks fs ls
            #databricks fs rm 'dbfs:/FileStore/dev/artifacts/'
            #databricks fs cp -r dbkframework-1-py3-none-any.whl dbfs:/FileStore/dev/artifacts/

            #databricks libraries uninstall --cluster-id {cluster_id} --whl dbfs:/FileStore/dev/artifacts/dbkframework-1-py3-none-any.whl
            #databricks libraries install --cluster-id {cluster_id} --whl dbfs:/FileStore/dev/artifacts/dbkframework-1-py3-none-any.whl

          #shell: bash

          
        
